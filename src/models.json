[
	{
		"created_at": "2024-02-06 18:16:27.183",
		"description": "Deepseek Coder is composed of a series of code language models, each trained from scratch on 2T tokens, with a composition of 87% code and 13% natural language in both English and Chinese.",
		"id": "7f180530-2e16-4116-9d26-f49fbed9d372",
		"name": "@hf/thebloke/deepseek-coder-6.7b-base-awq",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "4096" },
			{
				"property_id": "terms",
				"value": "https://huggingface.co/TheBloke/deepseek-coder-6.7B-base-AWQ"
			}
		],
		"source": 2,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-02-06 18:18:27.462",
		"description": "Deepseek Coder is composed of a series of code language models, each trained from scratch on 2T tokens, with a composition of 87% code and 13% natural language in both English and Chinese.",
		"id": "60474554-f03b-4ff4-8ecc-c1b7c71d7b29",
		"name": "@hf/thebloke/deepseek-coder-6.7b-instruct-awq",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "4096" },
			{
				"property_id": "terms",
				"value": "https://huggingface.co/TheBloke/deepseek-coder-6.7B-instruct-AWQ"
			}
		],
		"source": 2,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-02-27 17:54:17.459",
		"description": "DeepSeekMath-Instruct 7B is a mathematically instructed tuning model derived from DeepSeekMath-Base 7B. DeepSeekMath is initialized with DeepSeek-Coder-v1.5 7B and continues pre-training on math-related tokens sourced from Common Crawl, together with natural language and code data for 500B tokens.",
		"id": "4c3a544e-da47-4336-9cea-c7cbfab33f16",
		"name": "@cf/deepseek-ai/deepseek-math-7b-instruct",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "4096" },
			{
				"property_id": "info",
				"value": "https://huggingface.co/deepseek-ai/deepseek-math-7b-instruct"
			},
			{
				"property_id": "terms",
				"value": "https://github.com/deepseek-ai/DeepSeek-Math/blob/main/LICENSE-MODEL"
			}
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2025-01-22 19:48:55.776",
		"description": "DeepSeek-R1-Distill-Qwen-32B is a model distilled from DeepSeek-R1 based on Qwen2.5. It outperforms OpenAI-o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.",
		"id": "ad01ab83-baf8-4e7b-8fed-a0a219d4eb45",
		"name": "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b",
		"properties": [
			{ "property_id": "context_window", "value": "80000" },
			{
				"property_id": "price",
				"value": [
					{ "currency": "USD", "price": 0.5, "unit": "per M input tokens" },
					{ "currency": "USD", "price": 4.88, "unit": "per M output tokens" }
				]
			},
			{
				"property_id": "terms",
				"value": "https://github.com/deepseek-ai/DeepSeek-R1/blob/main/LICENSE"
			}
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-02-27 18:23:05.178",
		"description": "DiscoLM German 7b is a Mistral-based large language model with a focus on German-language applications. AWQ is an efficient, accurate and blazing-fast low-bit weight quantization method, currently supporting 4-bit quantization.",
		"id": "9d2ab560-065e-4d0d-a789-d4bc7468d33e",
		"name": "@cf/thebloke/discolm-german-7b-v1-awq",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "4096" },
			{
				"property_id": "info",
				"value": "https://huggingface.co/TheBloke/DiscoLM_German_7b_v1-AWQ"
			}
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-02-27 18:21:15.796",
		"description": "Falcon-7B-Instruct is a 7B parameters causal decoder-only model built by TII based on Falcon-7B and finetuned on a mixture of chat/instruct datasets.",
		"id": "48dd2443-0c61-43b2-8894-22abddf1b081",
		"name": "@cf/tiiuae/falcon-7b-instruct",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "4096" },
			{ "property_id": "info", "value": "https://huggingface.co/tiiuae/falcon-7b-instruct" }
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2025-03-18 03:58:02.423",
		"description": "Gemma 3 models are well-suited for a variety of text generation and image understanding tasks, including question answering, summarization, and reasoning. Gemma 3 models are multimodal, handling text and image input and generating text output, with a large, 128K context window, multilingual support in over 140 languages, and is available in more sizes than previous versions.",
		"id": "053d5ac0-861b-4d3b-8501-e58d00417ef8",
		"name": "@cf/google/gemma-3-12b-it",
		"properties": [
			{ "property_id": "context_window", "value": "80000" },
			{
				"property_id": "price",
				"value": [
					{ "currency": "USD", "price": 0.35, "unit": "per M input tokens" },
					{ "currency": "USD", "price": 0.56, "unit": "per M output tokens" }
				]
			},
			{ "property_id": "lora", "value": "true" }
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-04-01 23:51:35.866",
		"description": "Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models. They are text-to-text, decoder-only large language models, available in English, with open weights, pre-trained variants, and instruction-tuned variants.",
		"id": "0f002249-7d86-4698-aabf-8529ed86cefb",
		"name": "@hf/google/gemma-7b-it",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "8192" },
			{ "property_id": "info", "value": "https://ai.google.dev/gemma/docs" },
			{ "property_id": "lora", "value": "true" },
			{ "property_id": "terms", "value": "https://ai.google.dev/gemma/terms" }
		],
		"source": 2,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-04-01 23:45:53.800",
		"description": "Hermes 2 Pro on Mistral 7B is the new flagship 7B Hermes! Hermes 2 Pro is an upgraded, retrained version of Nous Hermes 2, consisting of an updated and cleaned version of the OpenHermes 2.5 Dataset, as well as a newly introduced Function Calling and JSON Mode dataset developed in-house.",
		"id": "44774b85-08c8-4bb8-8d2a-b06ebc538a79",
		"name": "@hf/nousresearch/hermes-2-pro-mistral-7b",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "24000" },
			{ "property_id": "function_calling", "value": "true" },
			{
				"property_id": "info",
				"value": "https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B"
			}
		],
		"source": 2,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2023-11-24 00:27:15.869",
		"description": "Llama 2 13B Chat AWQ is an efficient, accurate and blazing-fast low-bit weight quantized Llama 2 variant.",
		"id": "85c5a3c6-24b0-45e7-b23a-023182578822",
		"name": "@hf/thebloke/llama-2-13b-chat-awq",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "4096" },
			{
				"property_id": "info",
				"value": "https://huggingface.co/TheBloke/Llama-2-13B-chat-AWQ"
			}
		],
		"source": 2,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2023-11-07 11:54:20.229",
		"description": "Full precision (fp16) generative text model with 7 billion parameters from Meta",
		"id": "ca54bcd6-0d98-4739-9b3b-5c8b4402193d",
		"name": "@cf/meta/llama-2-7b-chat-fp16",
		"properties": [
			{
				"property_id": "price",
				"value": [
					{ "currency": "USD", "price": 0.56, "unit": "per M input tokens" },
					{ "currency": "USD", "price": 6.67, "unit": "per M output tokens" }
				]
			},
			{ "property_id": "context_window", "value": "4096" },
			{ "property_id": "info", "value": "https://ai.meta.com/llama/" },
			{
				"property_id": "terms",
				"value": "https://ai.meta.com/resources/models-and-libraries/llama-downloads/"
			}
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2023-09-25 19:21:11.898",
		"description": "Quantized (int8) generative text model with 7 billion parameters from Meta",
		"id": "9c95c39d-45b3-4163-9631-22f0c0dc3b14",
		"name": "@cf/meta/llama-2-7b-chat-int8",
		"properties": [{ "property_id": "context_window", "value": "8192" }],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-04-18 20:31:47.273",
		"description": "Generation over generation, Meta Llama 3 demonstrates state-of-the-art performance on a wide range of industry benchmarks and offers new capabilities, including improved reasoning.",
		"id": "e11d8f45-7b08-499a-9eeb-71d4d3c8cbf9",
		"name": "@cf/meta/llama-3-8b-instruct",
		"properties": [
			{
				"property_id": "price",
				"value": [
					{ "currency": "USD", "price": 0.28, "unit": "per M input tokens" },
					{ "currency": "USD", "price": 0.83, "unit": "per M output tokens" }
				]
			},
			{ "property_id": "context_window", "value": "7968" },
			{ "property_id": "info", "value": "https://llama.meta.com" },
			{ "property_id": "terms", "value": "https://llama.meta.com/llama3/license/#" }
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-05-09 23:32:47.584",
		"description": "Quantized (int4) generative text model with 8 billion parameters from Meta.",
		"id": "31097538-a3ff-4e6e-bb56-ad0e1f428b61",
		"name": "@cf/meta/llama-3-8b-instruct-awq",
		"properties": [
			{
				"property_id": "price",
				"value": [
					{ "currency": "USD", "price": 0.12, "unit": "per M input tokens" },
					{ "currency": "USD", "price": 0.27, "unit": "per M output tokens" }
				]
			},
			{ "property_id": "context_window", "value": "8192" },
			{ "property_id": "info", "value": "https://llama.meta.com" },
			{ "property_id": "terms", "value": "https://llama.meta.com/llama3/license/#" }
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-07-25 17:46:04.304",
		"description": "Quantized (int4) generative text model with 8 billion parameters from Meta.\n",
		"id": "3dcb4f2d-26a8-412b-b6e3-2a368beff66b",
		"name": "@cf/meta/llama-3.1-8b-instruct-awq",
		"properties": [
			{
				"property_id": "price",
				"value": [
					{ "currency": "USD", "price": 0.12, "unit": "per M input tokens" },
					{ "currency": "USD", "price": 0.27, "unit": "per M output tokens" }
				]
			},
			{ "property_id": "context_window", "value": "8192" },
			{
				"property_id": "terms",
				"value": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/LICENSE"
			}
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-07-25 17:28:43.328",
		"description": "Llama 3.1 8B quantized to FP8 precision",
		"id": "9b9c87c6-d4b7-494c-b177-87feab5904db",
		"name": "@cf/meta/llama-3.1-8b-instruct-fp8",
		"properties": [
			{
				"property_id": "price",
				"value": [
					{ "currency": "USD", "price": 0.15, "unit": "per M input tokens" },
					{ "currency": "USD", "price": 0.29, "unit": "per M output tokens" }
				]
			},
			{ "property_id": "context_window", "value": "32000" },
			{
				"property_id": "terms",
				"value": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/LICENSE"
			}
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-09-25 05:36:04.547",
		"description": " The Llama 3.2-Vision instruction-tuned models are optimized for visual recognition, image reasoning, captioning, and answering general questions about an image.",
		"id": "2cbc033b-ded8-4e02-bbb2-47cf05d5cfe5",
		"name": "@cf/meta/llama-3.2-11b-vision-instruct",
		"properties": [
			{ "property_id": "context_window", "value": "128000" },
			{
				"property_id": "price",
				"value": [
					{ "currency": "USD", "price": 0.049, "unit": "per M input tokens" },
					{ "currency": "USD", "price": 0.68, "unit": "per M output tokens" }
				]
			},
			{ "property_id": "lora", "value": "true" },
			{
				"property_id": "terms",
				"value": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/LICENSE"
			}
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-09-25 21:36:32.050",
		"description": "The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks.",
		"id": "906a57fd-b018-4d6c-a43e-a296d4cc5839",
		"name": "@cf/meta/llama-3.2-1b-instruct",
		"properties": [
			{
				"property_id": "price",
				"value": [
					{ "currency": "USD", "price": 0.027, "unit": "per M input tokens" },
					{ "currency": "USD", "price": 0.2, "unit": "per M output tokens" }
				]
			},
			{ "property_id": "context_window", "value": "60000" },
			{
				"property_id": "terms",
				"value": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/LICENSE"
			}
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-09-25 20:05:43.986",
		"description": "The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks.",
		"id": "d9dc8363-66f4-4bb0-8641-464ee7bfc131",
		"name": "@cf/meta/llama-3.2-3b-instruct",
		"properties": [
			{
				"property_id": "price",
				"value": [
					{ "currency": "USD", "price": 0.051, "unit": "per M input tokens" },
					{ "currency": "USD", "price": 0.34, "unit": "per M output tokens" }
				]
			},
			{ "property_id": "context_window", "value": "128000" },
			{
				"property_id": "terms",
				"value": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/LICENSE"
			}
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-12-06 17:09:18.338",
		"description": "Llama 3.3 70B quantized to fp8 precision, optimized to be faster.",
		"id": "7a143886-c9bb-4a1c-be95-377b1973bc3b",
		"name": "@cf/meta/llama-3.3-70b-instruct-fp8-fast",
		"properties": [
			{ "property_id": "async_queue", "value": "true" },
			{ "property_id": "context_window", "value": "24000" },
			{
				"property_id": "price",
				"value": [
					{ "currency": "USD", "price": 0.29, "unit": "per M input tokens" },
					{ "currency": "USD", "price": 2.25, "unit": "per M output tokens" }
				]
			},
			{ "property_id": "function_calling", "value": "true" },
			{
				"property_id": "terms",
				"value": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/LICENSE"
			}
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2025-04-05 20:25:56.137",
		"description": "Meta's Llama 4 Scout is a 17 billion parameter model with 16 experts that is natively multimodal. These models leverage a mixture-of-experts architecture to offer industry-leading performance in text and image understanding.",
		"id": "06455e78-19f7-487b-93cd-c05a3dd07813",
		"name": "@cf/meta/llama-4-scout-17b-16e-instruct",
		"properties": [
			{ "property_id": "context_window", "value": "131000" },
			{
				"property_id": "price",
				"value": [
					{ "currency": "USD", "price": 0.27, "unit": "per M input tokens" },
					{ "currency": "USD", "price": 0.85, "unit": "per M output tokens" }
				]
			},
			{ "property_id": "function_calling", "value": "true" },
			{
				"property_id": "terms",
				"value": "https://github.com/meta-llama/llama-models/blob/main/models/llama4/LICENSE"
			}
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2025-01-22 23:26:23.495",
		"description": "Llama Guard 3 is a Llama-3.1-8B pretrained model, fine-tuned for content safety classification. Similar to previous versions, it can be used to classify content in both LLM inputs (prompt classification) and in LLM responses (response classification). It acts as an LLM – it generates text in its output that indicates whether a given prompt or response is safe or unsafe, and if unsafe, it also lists the content categories violated.",
		"id": "cc80437b-9a8d-4f1a-9c77-9aaf0d226922",
		"name": "@cf/meta/llama-guard-3-8b",
		"properties": [
			{
				"property_id": "price",
				"value": [
					{ "currency": "USD", "price": 0.48, "unit": "per M input tokens" },
					{ "currency": "USD", "price": 0.03, "unit": "per M output tokens" }
				]
			},
			{ "property_id": "lora", "value": "true" }
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-02-06 18:13:59.060",
		"description": "Llama Guard is a model for classifying the safety of LLM prompts and responses, using a taxonomy of safety risks.\n",
		"id": "d9b7a55c-cefa-4208-8ab3-11497a2b046c",
		"name": "@hf/thebloke/llamaguard-7b-awq",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "4096" }
		],
		"source": 2,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-05-22 18:21:04.371",
		"description": "Generation over generation, Meta Llama 3 demonstrates state-of-the-art performance on a wide range of industry benchmarks and offers new capabilities, including improved reasoning.\t",
		"id": "1a7b6ad6-9987-4bd3-a329-20ee8de93296",
		"name": "@hf/meta-llama/meta-llama-3-8b-instruct",
		"properties": [{ "property_id": "context_window", "value": "8192" }],
		"source": 2,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2023-11-07 11:54:20.229",
		"description": "Instruct fine-tuned version of the Mistral-7b generative text model with 7 billion parameters",
		"finetunes": [
			{
				"created_at": "2024-05-08 02:23:55.897",
				"description": "LoRA adapter that enables Mistral to generate code",
				"id": "39fb185c-762a-4633-a2ad-7a4462940608",
				"model": "@cf/mistral/mistral-7b-instruct-v0.2-lora",
				"modified_at": "2024-05-08 02:23:55.897",
				"name": "cf-public-magicoder",
				"public": 1
			},
			{
				"created_at": "2024-05-09 02:11:12.386",
				"description": "LoRA adapter that enables Mistral to summarize articles. https://huggingface.co/predibase/cnn",
				"id": "911a83cf-d947-4c96-b4d2-a86c2c6d2b7f",
				"model": "@cf/mistral/mistral-7b-instruct-v0.2-lora",
				"modified_at": "2024-05-09 02:11:12.386",
				"name": "cf-public-cnn-summarization",
				"public": 1
			},
			{
				"created_at": "2024-05-09 02:19:48.750",
				"description": "LoRA adapter that enables Mistral to detect and classify toxic comments. https://huggingface.co/predibase/jigsaw",
				"id": "c0b52d28-530b-4751-b7d9-afbdb4795990",
				"model": "@cf/mistral/mistral-7b-instruct-v0.2-lora",
				"modified_at": "2024-05-09 02:19:48.750",
				"name": "cf-public-jigsaw-classification",
				"public": 1
			}
		],
		"id": "c907d0f9-d69d-4e93-b501-4daeb4fd69eb",
		"name": "@cf/mistral/mistral-7b-instruct-v0.1",
		"properties": [
			{
				"property_id": "price",
				"value": [
					{ "currency": "USD", "price": 0.11, "unit": "per M input tokens" },
					{ "currency": "USD", "price": 0.19, "unit": "per M output tokens" }
				]
			},
			{ "property_id": "context_window", "value": "2824" },
			{ "property_id": "info", "value": "https://mistral.ai/news/announcing-mistral-7b/" },
			{ "property_id": "lora", "value": "true" }
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2023-11-24 00:27:15.869",
		"description": "Mistral 7B Instruct v0.1 AWQ is an efficient, accurate and blazing-fast low-bit weight quantized Mistral variant.",
		"id": "980ec5e9-33c2-483a-a2d8-cd092fdf273f",
		"name": "@hf/thebloke/mistral-7b-instruct-v0.1-awq",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "4096" },
			{
				"property_id": "info",
				"value": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-AWQ"
			}
		],
		"source": 2,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-04-02 13:00:59.244",
		"description": "The Mistral-7B-Instruct-v0.2 Large Language Model (LLM) is an instruct fine-tuned version of the Mistral-7B-v0.2. Mistral-7B-v0.2 has the following changes compared to Mistral-7B-v0.1: 32k context window (vs 8k context in v0.1), rope-theta = 1e6, and no Sliding-Window Attention.",
		"finetunes": [
			{
				"created_at": "2024-05-08 02:23:55.897",
				"description": "LoRA adapter that enables Mistral to generate code",
				"id": "39fb185c-762a-4633-a2ad-7a4462940608",
				"model": "@cf/mistral/mistral-7b-instruct-v0.2-lora",
				"modified_at": "2024-05-08 02:23:55.897",
				"name": "cf-public-magicoder",
				"public": 1
			},
			{
				"created_at": "2024-05-09 02:11:12.386",
				"description": "LoRA adapter that enables Mistral to summarize articles. https://huggingface.co/predibase/cnn",
				"id": "911a83cf-d947-4c96-b4d2-a86c2c6d2b7f",
				"model": "@cf/mistral/mistral-7b-instruct-v0.2-lora",
				"modified_at": "2024-05-09 02:11:12.386",
				"name": "cf-public-cnn-summarization",
				"public": 1
			},
			{
				"created_at": "2024-05-09 02:19:48.750",
				"description": "LoRA adapter that enables Mistral to detect and classify toxic comments. https://huggingface.co/predibase/jigsaw",
				"id": "c0b52d28-530b-4751-b7d9-afbdb4795990",
				"model": "@cf/mistral/mistral-7b-instruct-v0.2-lora",
				"modified_at": "2024-05-09 02:19:48.750",
				"name": "cf-public-jigsaw-classification",
				"public": 1
			}
		],
		"id": "b97d7069-48d9-461c-80dd-445d20a632eb",
		"name": "@hf/mistral/mistral-7b-instruct-v0.2",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "3072" },
			{
				"property_id": "info",
				"value": "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2"
			},
			{ "property_id": "lora", "value": "true" },
			{ "property_id": "max_batch_prefill_tokens", "value": "8192" },
			{ "property_id": "max_input_length", "value": "3072" },
			{ "property_id": "max_total_tokens", "value": "4096" }
		],
		"source": 2,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2025-03-18 03:28:37.890",
		"description": "Building upon Mistral Small 3 (2501), Mistral Small 3.1 (2503) adds state-of-the-art vision understanding and enhances long context capabilities up to 128k tokens without compromising text performance. With 24 billion parameters, this model achieves top-tier capabilities in both text and vision tasks.",
		"id": "31690291-ebdc-4f98-bcfc-a44844e215b7",
		"name": "@cf/mistralai/mistral-small-3.1-24b-instruct",
		"properties": [
			{ "property_id": "context_window", "value": "128000" },
			{
				"property_id": "price",
				"value": [
					{ "currency": "USD", "price": 0.35, "unit": "per M input tokens" },
					{ "currency": "USD", "price": 0.56, "unit": "per M output tokens" }
				]
			},
			{ "property_id": "function_calling", "value": "true" }
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-02-06 18:12:30.722",
		"description": "This model is a fine-tuned 7B parameter LLM on the Intel Gaudi 2 processor from the mistralai/Mistral-7B-v0.1 on the open source dataset Open-Orca/SlimOrca.",
		"id": "d2ba5c6b-bbb7-49d6-b466-900654870cd6",
		"name": "@hf/thebloke/neural-chat-7b-v3-1-awq",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "4096" }
		],
		"source": 2,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-02-27 18:20:39.169",
		"description": "OpenChat is an innovative library of open-source language models, fine-tuned with C-RLFT - a strategy inspired by offline reinforcement learning.",
		"id": "081054cd-a254-4349-855e-6dc0996277fa",
		"name": "@cf/openchat/openchat-3.5-0106",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "8192" },
			{ "property_id": "info", "value": "https://huggingface.co/openchat/openchat-3.5-0106" }
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-02-06 18:04:22.846",
		"description": "OpenHermes 2.5 Mistral 7B is a state of the art Mistral Fine-tune, a continuation of OpenHermes 2 model, which trained on additional code datasets.",
		"id": "673c56cc-8553-49a1-b179-dd549ec9209a",
		"name": "@hf/thebloke/openhermes-2.5-mistral-7b-awq",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "4096" }
		],
		"source": 2,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-02-27 18:26:21.126",
		"description": "Phi-2 is a Transformer-based model with a next-word prediction objective, trained on 1.4T tokens from multiple passes on a mixture of Synthetic and Web datasets for NLP and coding.",
		"id": "1d933df3-680f-4280-940d-da87435edb07",
		"name": "@cf/microsoft/phi-2",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "2048" },
			{ "property_id": "info", "value": "https://huggingface.co/microsoft/phi-2" }
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-02-27 18:23:37.344",
		"description": "Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud.",
		"id": "f8703a00-ed54-4f98-bdc3-cd9a813286f3",
		"name": "@cf/qwen/qwen1.5-0.5b-chat",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "32000" },
			{ "property_id": "info", "value": "https://huggingface.co/qwen/qwen1.5-0.5b-chat" }
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-02-27 18:30:31.723",
		"description": "Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud.",
		"id": "3222ddb3-e211-4fd9-9a6d-79a80e47b3a6",
		"name": "@cf/qwen/qwen1.5-1.8b-chat",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "32000" },
			{ "property_id": "info", "value": "https://huggingface.co/qwen/qwen1.5-1.8b-chat" }
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-02-27 18:24:45.316",
		"description": "Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud. AWQ is an efficient, accurate and blazing-fast low-bit weight quantization method, currently supporting 4-bit quantization.",
		"id": "09d113a9-03c4-420e-b6f2-52ad4b3bed45",
		"name": "@cf/qwen/qwen1.5-14b-chat-awq",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "7500" },
			{ "property_id": "info", "value": "https://huggingface.co/qwen/qwen1.5-14b-chat-awq" }
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-02-27 18:24:11.709",
		"description": "Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud. AWQ is an efficient, accurate and blazing-fast low-bit weight quantization method, currently supporting 4-bit quantization.",
		"id": "90a20ae7-7cf4-4eb3-8672-8fc4ee580635",
		"name": "@cf/qwen/qwen1.5-7b-chat-awq",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "20000" },
			{ "property_id": "info", "value": "https://huggingface.co/qwen/qwen1.5-7b-chat-awq" }
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2025-02-27 00:31:43.829",
		"description": "Qwen2.5-Coder is the latest series of Code-Specific Qwen large language models (formerly known as CodeQwen). As of now, Qwen2.5-Coder has covered six mainstream model sizes, 0.5, 1.5, 3, 7, 14, 32 billion parameters, to meet the needs of different developers. Qwen2.5-Coder brings the following improvements upon CodeQwen1.5:",
		"id": "51b71d5b-8bc0-4489-a107-95e542b69914",
		"name": "@cf/qwen/qwen2.5-coder-32b-instruct",
		"properties": [
			{ "property_id": "context_window", "value": "32768" },
			{
				"property_id": "price",
				"value": [
					{ "currency": "USD", "price": 0.66, "unit": "per M input tokens" },
					{ "currency": "USD", "price": 1, "unit": "per M output tokens" }
				]
			},
			{ "property_id": "lora", "value": "true" }
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2025-03-05 21:52:40.974",
		"description": "QwQ is the reasoning model of the Qwen series. Compared with conventional instruction-tuned models, QwQ, which is capable of thinking and reasoning, can achieve significantly enhanced performance in downstream tasks, especially hard problems. QwQ-32B is the medium-sized reasoning model, which is capable of achieving competitive performance against state-of-the-art reasoning models, e.g., DeepSeek-R1, o1-mini.",
		"id": "02c16efa-29f5-4304-8e6c-3d188889f875",
		"name": "@cf/qwen/qwq-32b",
		"properties": [
			{ "property_id": "context_window", "value": "24000" },
			{
				"property_id": "price",
				"value": [
					{ "currency": "USD", "price": 0.66, "unit": "per M input tokens" },
					{ "currency": "USD", "price": 1, "unit": "per M output tokens" }
				]
			},
			{ "property_id": "lora", "value": "true" }
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-02-27 18:18:46.095",
		"description": "This model is intended to be used by non-technical users to understand data inside their SQL databases. ",
		"id": "1dc9e589-df6b-4e66-ac9f-ceff42d64983",
		"name": "@cf/defog/sqlcoder-7b-2",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "10000" },
			{ "property_id": "info", "value": "https://huggingface.co/defog/sqlcoder-7b-2" },
			{
				"property_id": "terms",
				"value": "https://creativecommons.org/licenses/by-sa/4.0/deed.en"
			}
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-04-01 23:49:31.797",
		"description": "We introduce Starling-LM-7B-beta, an open large language model (LLM) trained by Reinforcement Learning from AI Feedback (RLAIF). Starling-LM-7B-beta is trained from Openchat-3.5-0106 with our new reward model Nexusflow/Starling-RM-34B and policy optimization method Fine-Tuning Language Models from Human Preferences (PPO).",
		"id": "e5ca943b-720f-4e66-aa8f-40e3d2770933",
		"name": "@hf/nexusflow/starling-lm-7b-beta",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "4096" },
			{
				"property_id": "info",
				"value": "https://huggingface.co/Nexusflow/Starling-LM-7B-beta"
			},
			{ "property_id": "max_batch_prefill_tokens", "value": "8192" },
			{ "property_id": "max_input_length", "value": "3072" },
			{ "property_id": "max_total_tokens", "value": "4096" }
		],
		"source": 2,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-02-27 18:25:37.524",
		"description": "The TinyLlama project aims to pretrain a 1.1B Llama model on 3 trillion tokens. This is the chat model finetuned on top of TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T.",
		"id": "bf6ddd21-6477-4681-bbbe-24c3d5423e78",
		"name": "@cf/tinyllama/tinyllama-1.1b-chat-v1.0",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "2048" },
			{
				"property_id": "info",
				"value": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0"
			}
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2024-04-24 14:37:19.494",
		"description": "Cybertron 7B v2 is a 7B MistralAI based model, best on it's series. It was trained with SFT, DPO and UNA (Unified Neural Alignment) on multiple datasets.",
		"id": "b7fe7ad2-aeaf-47d2-8bfa-7a5ae22a2ab4",
		"name": "@cf/fblgit/una-cybertron-7b-v2-bf16",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "15000" }
		],
		"source": 1,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	},
	{
		"created_at": "2023-11-24 00:27:15.869",
		"description": "Zephyr 7B Beta AWQ is an efficient, accurate and blazing-fast low-bit weight quantized Zephyr model variant.",
		"id": "3976bab8-3810-4ad8-8580-ab1e22de7823",
		"name": "@hf/thebloke/zephyr-7b-beta-awq",
		"properties": [
			{ "property_id": "beta", "value": "true" },
			{ "property_id": "context_window", "value": "4096" },
			{ "property_id": "info", "value": "https://huggingface.co/TheBloke/zephyr-7B-beta-AWQ" }
		],
		"source": 2,
		"tags": [],
		"task": {
			"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks.",
			"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
			"name": "Text Generation"
		}
	}
]
